---
interact_link: content/lessons/therightfit.ipynb
kernel_name: python3
kernel_path: content/lessons
has_widgets: false
title: |-
  Lessons
pagenum: 0
prev_page:
  url: 
next_page:
  url: 
suffix: .ipynb
search: machine learning learn www kaggle com tree model data intro just function step maxleafnodes using random forests home page fit explanation underfitting below decision set stuff getmae values value accurate size going even youve models forum right add cheesy code hidden basically provides hyperparameter analysis trees identify want send me tomorrow try github needs done back end ignore demo thanks much exercises yourself well supply same read previous lesson run cell compare different sizes loop tries following possible store output allows select gives best deploy practice keeping dont need hold validation made modeling decisions tuned improved results still not very

comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---

    <main class="jupyter-page">
    <div id="page-info"><div id="page-title">Lessons</div>
</div>
    <div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong><a href="https://www.kaggle.com/learn/intro-to-machine-learning">Machine Learning Home Page</a></strong></p>
<hr>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-Right-Fit">The Right Fit<a class="anchor-link" href="#The-Right-Fit"> </a></h2><p>Add cheesy explanation of over/underfitting.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The code below will be hidden but is basically provides a way to do hyperparameter analysis with decision trees. I can write the explanation as a way to identify over/underfitting if you want to do an intro? You can just write it and send it to me. Tomorrow I can try and set you up with all the github stuff that needs to be done on the back-end. And just ignore demo stuff. Thanks so much!</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Code you have previously used to load data</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>


<span class="c1"># Path of the file to read</span>
<span class="n">iowa_file_path</span> <span class="o">=</span> <span class="s1">&#39;https://raw.githubusercontent.com/UncertainQubit/firstrepo/master/train.csv&#39;</span>

<span class="n">home_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">iowa_file_path</span><span class="p">)</span>
<span class="c1"># Create target object and call it y</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">home_data</span><span class="o">.</span><span class="n">SalePrice</span>
<span class="c1"># Create X</span>
<span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;LotArea&#39;</span><span class="p">,</span> <span class="s1">&#39;YearBuilt&#39;</span><span class="p">,</span> <span class="s1">&#39;1stFlrSF&#39;</span><span class="p">,</span> <span class="s1">&#39;2ndFlrSF&#39;</span><span class="p">,</span> <span class="s1">&#39;FullBath&#39;</span><span class="p">,</span> <span class="s1">&#39;BedroomAbvGr&#39;</span><span class="p">,</span> <span class="s1">&#39;TotRmsAbvGrd&#39;</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">home_data</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>

<span class="c1"># Split into validation and training data</span>
<span class="n">train_X</span><span class="p">,</span> <span class="n">val_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">val_y</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Specify Model</span>
<span class="n">iowa_model</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># Fit Model</span>
<span class="n">iowa_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>

<span class="c1"># Make validation predictions and calculate mean absolute error</span>
<span class="n">val_predictions</span> <span class="o">=</span> <span class="n">iowa_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">val_X</span><span class="p">)</span>
<span class="n">val_mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">val_predictions</span><span class="p">,</span> <span class="n">val_y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Validation MAE: </span><span class="si">{:,.0f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">val_mae</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Validation MAE: 29,653
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Exercises">Exercises<a class="anchor-link" href="#Exercises"> </a></h1><p>You could write the function <code>get_mae</code> yourself. For now, we'll supply it. This is the same function you read about in the previous lesson. Just run the cell below.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_mae</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="p">,</span> <span class="n">train_X</span><span class="p">,</span> <span class="n">val_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">val_y</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="o">=</span><span class="n">max_leaf_nodes</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>
    <span class="n">preds_val</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">val_X</span><span class="p">)</span>
    <span class="n">mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">val_y</span><span class="p">,</span> <span class="n">preds_val</span><span class="p">)</span>
    <span class="k">return</span><span class="p">(</span><span class="n">mae</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Step-1:-Compare-Different-Tree-Sizes">Step 1: Compare Different Tree Sizes<a class="anchor-link" href="#Step-1:-Compare-Different-Tree-Sizes"> </a></h2><p>Write a loop that tries the following values for <em>max_leaf_nodes</em> from a set of possible values.</p>
<p>Call the <em>get_mae</em> function on each value of max_leaf_nodes. Store the output in some way that allows you to select the value of <code>max_leaf_nodes</code> that gives the most accurate model on your data.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">candidate_max_leaf_nodes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">250</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">2000</span><span class="p">]</span>
<span class="c1"># Write loop to find the ideal tree size from candidate_max_leaf_nodes</span>
<span class="n">_</span>
<span class="n">scores</span> <span class="o">=</span> <span class="p">{</span><span class="n">leaf_size</span><span class="p">:</span> <span class="n">get_mae</span><span class="p">(</span><span class="n">leaf_size</span><span class="p">,</span> <span class="n">train_X</span><span class="p">,</span> <span class="n">val_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">val_y</span><span class="p">)</span> <span class="k">for</span> <span class="n">leaf_size</span> <span class="ow">in</span> <span class="n">candidate_max_leaf_nodes</span><span class="p">}</span>
<span class="n">best_tree_size</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">scores</span><span class="o">.</span><span class="n">get</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">best_tree_size</span><span class="p">)</span>
<span class="c1"># Store the best value of max_leaf_nodes (it will be either 5, 25, 50, 100, 250 or 500)</span>
<span class="n">best_tree_size</span> <span class="o">=</span> <span class="mi">100</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>100
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-intense-fg ansi-bold">---------------------------------------------------------------------------</span>
<span class="ansi-red-intense-fg ansi-bold">AttributeError</span>                            Traceback (most recent call last)
<span class="ansi-green-intense-fg ansi-bold">&lt;ipython-input-8-66776fb232c1&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-intense-fg ansi-bold">()</span>
<span class="ansi-green-fg">     12</span> get_ipython<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-yellow-intense-fg ansi-bold">)</span><span class="ansi-yellow-intense-fg ansi-bold">.</span>run_line_magic<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-blue-intense-fg ansi-bold">&#39;matplotlib&#39;</span><span class="ansi-yellow-intense-fg ansi-bold">,</span> <span class="ansi-blue-intense-fg ansi-bold">&#39;inline&#39;</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">     13</span> <span class="ansi-green-intense-fg ansi-bold">import</span> seaborn <span class="ansi-green-intense-fg ansi-bold">as</span> sns
<span class="ansi-green-intense-fg ansi-bold">---&gt; 14</span><span class="ansi-yellow-intense-fg ansi-bold"> </span>sns<span class="ansi-yellow-intense-fg ansi-bold">.</span>scatterplot<span class="ansi-yellow-intense-fg ansi-bold">(</span>x<span class="ansi-yellow-intense-fg ansi-bold">=</span>candidate_max_leaf_nodes<span class="ansi-yellow-intense-fg ansi-bold">,</span> y<span class="ansi-yellow-intense-fg ansi-bold">=</span>scores<span class="ansi-yellow-intense-fg ansi-bold">)</span>

<span class="ansi-red-intense-fg ansi-bold">AttributeError</span>: module &#39;seaborn&#39; has no attribute &#39;scatterplot&#39;</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Step-2:-Fit-Model-Using-All-Data">Step 2: Fit Model Using All Data<a class="anchor-link" href="#Step-2:-Fit-Model-Using-All-Data"> </a></h2><p>You know the best tree size. If you were going to deploy this model in practice, you would make it even more accurate by using all of the data and keeping that tree size.  That is, you don't need to hold out the validation data now that you've made all your modeling decisions.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Fill in argument to make optimal size and uncomment</span>
<span class="n">final_model</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span> <span class="o">=</span> <span class="n">best_tree_size</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>

<span class="c1"># fit the final model and uncomment the next two lines</span>
<span class="n">final_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>DecisionTreeRegressor(criterion=&#39;mse&#39;, max_depth=None, max_features=None,
           max_leaf_nodes=100, min_impurity_decrease=0.0,
           min_impurity_split=None, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           presort=False, random_state=0, splitter=&#39;best&#39;)</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You've tuned this model and improved your results. But we are still using Decision Tree models, which are not very sophisticated by modern machine learning standards. In the next step you will learn to use Random Forests to improve your models even more.</p>
<h1 id="Keep-Going">Keep Going<a class="anchor-link" href="#Keep-Going"> </a></h1><p>You are ready for <strong><a href="https://www.kaggle.com/dansbecker/random-forests">Random Forests</a>.</strong></p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<p><strong><a href="https://www.kaggle.com/learn/intro-to-machine-learning">Machine Learning Home Page</a></strong></p>
<p><em>Have questions or comments? Visit the <a href="https://www.kaggle.com/learn-forum">Learn Discussion forum</a> to chat with other Learners.</em></p>

</div>
</div>
</div>
</div>

 


    </main>
    